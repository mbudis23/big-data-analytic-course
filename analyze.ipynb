{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from pyspark.sql.functions import when, col, expr, regexp_replace, explode\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "import pandas as pd\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"SentimentAnalyzeTwitter\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_path = \"hdfs://localhost:9000/project-uts/dataset_penyisihan_bdc_2024.csv\"\n",
    "df_test_path = \"hdfs://localhost:9000/project-uts/zaken.csv\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = spark.read.csv(df_train_path, header=True, sep=';')\n",
    "df_test = spark.read.csv(df_test_path, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "df_train = df_train.withColumn(\"text\", lower(df_train[\"text\"]))\n",
    "df_train = df_train.withColumn(\"label\", lower(df_train[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping label to label_indexed: {'politik': 0, 'sosial budaya': 1, 'pertahanan dan keamanan': 2, 'ideologi': 3, 'ekonomi': 4, 'sumber daya alam': 5, 'demografi': 6, 'geografi': 7}\n",
      "Mapping prediction to label: {0: 'politik', 1: 'sosial budaya', 2: 'pertahanan dan keamanan', 3: 'ideologi', 4: 'ekonomi', 5: 'sumber daya alam', 6: 'demografi', 7: 'geografi'}\n"
     ]
    }
   ],
   "source": [
    "# Label Encoding\n",
    "valid_labels = [\"politik\", \"sosial budaya\", \"pertahanan dan keamanan\", \"ideologi\", \"ekonomi\", \"sumber daya alam\", \"demografi\", \"geografi\"]\n",
    "\n",
    "df_train = df_train.filter(df_train.label.isin(valid_labels))\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"label\", outputCol=\"label_indexed\")\n",
    "indexer_model = indexer.fit(df_train)\n",
    "df_train = indexer_model.transform(df_train)\n",
    "labels_mapping = dict(zip(indexer_model.labels, range(len(indexer_model.labels))))\n",
    "print(\"Mapping label to label_indexed:\", labels_mapping)\n",
    "reverse_labels_mapping = {v: k for k, v in labels_mapping.items()}\n",
    "print(\"Mapping prediction to label:\", reverse_labels_mapping)\n",
    "df_train = df_train.drop(\"label\").withColumnRenamed(\"label_indexed\", \"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Retweet\n",
    "df_train = df_train.withColumn(\"retweet\", when(col(\"text\").contains(\"rt\"), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(replace(text, 'rt', ''))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Mention\n",
    "df_train = df_train.withColumn(\"mention\", when(col(\"text\").contains(\"@\"), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'@\\S+', '').alias(\"text\"))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Hashtag\n",
    "df_train = df_train.withColumn(\"hashtag\", when(col(\"text\").contains(\"#\"), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'#\\S+', '').alias(\"text\"))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check URL\n",
    "df_train = df_train.withColumn(\"url\", when(col(\"text\").rlike(r'https?://\\S+'), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'https?://\\S+', '').alias(\"text\"))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Reply\n",
    "df_train = df_train.withColumn(\"reply\", when(col(\"text\").rlike(r'\\[.*?\\]'), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\[.*?\\]', ''))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Candidate 01\n",
    "df_train = df_train.withColumn(\"candidate01\", when(col(\"text\").rlike(r'\\b(anies|baswedan|muhaimin|imin|iskandar|abah|amin|01|1)\\b'), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\b(anies|baswedan|muhaimin|imin|iskandar|abah|amin|01|1)\\b', '').alias(\"text\"))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Candidate 02\n",
    "df_train = df_train.withColumn(\"candidate02\", when(col(\"text\").rlike(r'\\b(prabowo|subianto|gibran|rakabuming|rakabumingraka|raka|pragib|prabowo-gibran|02|2)\\b'), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\b(prabowo|subianto|gibran|rakabuming|rakabumingraka|raka|pragib|prabowo-gibran|02|2)\\b', '').alias(\"text\"))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Candidate 03\n",
    "df_train = df_train.withColumn(\"candidate03\", when(col(\"text\").rlike(r'\\b(ganjar|pranowo|mahfud|md|prof|ganjar-pranowo|03|3)\\b'), True).otherwise(False))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\b(ganjar|pranowo|mahfud|md|prof|ganjar-pranowo|03|3)\\b', '').alias(\"text\"))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Whitespace\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'[^\\w\\s]', ''))\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\s+', ' '))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Number\n",
    "df_train = df_train.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\d+', ''))\n",
    "df_train = df_train.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Stopword\n",
    "stopwords_english = stopwords.words('english')\n",
    "stopwords_indo = stopwords.words('indonesian')\n",
    "stopwords_custom = ['duh', 'ya', 'emang', 'emng', 'sih', 'mas', 'wait','yang', 'yg', 'dan', 'atau', 'saya', 'kami', 'aku', 'kamu','dia','sok', 'juga','jg','dn','dgn','dg', 'dengan', 'hanya', 'hny', 'hnya', 'saja', 'sj' ,'kalo', 'kl', 'sekarang', 'skrg', 'nih', 'ini']\n",
    "all_stopwords = list(set(stopwords_english+stopwords_indo + stopwords_custom))\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words_token\")\n",
    "remover = StopWordsRemover(inputCol=\"words_token\", outputCol=\"filtered_words\", stopWords=all_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "hashing_tf = HashingTF(inputCol=\"filtered_words\", outputCol=\"raw_features\", numFeatures=2000)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ML\n",
    "lr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n",
    "pipeline = Pipeline(stages=[tokenizer, remover, hashing_tf, idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = pipeline.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr_model.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "|text                                                                                                                                                                                                                                                                                                                                                                                                                                                  |label|prediction|\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "|kunjungan ini untuk meresmikan dan menyerahkan proyek bantuan air bersih di lima titik                                                                                                                                                                                                                                                                                                                                                                |5.0  |5.0       |\n",
      "|dapat tepuk tangan meriah saat jadi rektor mewajibkan mata kuliah antikorupsi untuk memutus mata rantai korupsi                                                                                                                                                                                                                                                                                                                                       |0.0  |0.0       |\n",
      "|emng bener sih pendukung ada yg goblok begitu jg dg pendukung hnya sj menurut pak ridwan kamil skemanya terbalik klo mayoritas pendidikan menengah atas ainya ada jg pendidikan rendah yg milih                                                                                                                                                                                                                                                       |6.0  |6.0       |\n",
      "|sewaktu bersikap kritis ke kinerja pak dianggap engga sopan karena dianggap kurang menghormati orang tua giliran skrg yg tengil dan sok kritis malah dianggap kritis dan keras apakah ini tidak standar ganda                                                                                                                                                                                                                                         |0.0  |0.0       |\n",
      "|harap asn termasuk tni dan polri pegang sumpahnya dalam pemilu                                                                                                                                                                                                                                                                                                                                                                                        |0.0  |0.0       |\n",
      "|duh jangan sampai pak lurah denger nih di acara hajatan rakyat puluhan ribu warga di kendal serukan ganjar presiden kehadiran menjadi magnet bagi puluhan ribu warga untuk datang menghadiri hajatan rakyat besarnya antusiasme warga menjadi bukti bahwa jawa tengah tetap menjadi kandang banteng                                                                                                                                                   |0.0  |0.0       |\n",
      "|minta kemenhan dan tim satgas air unhan kaji bantuan air di sukabumi dekade                                                                                                                                                                                                                                                                                                                                                                           |2.0  |2.0       |\n",
      "|ya allah sibukkanlah orang zalim agar dapat kejahatan dari orang zalim lainnya                                                                                                                                                                                                                                                                                                                                                                        |0.0  |0.0       |\n",
      "|itu bapa kami bapa yg berikan perhatian untuk pendidikan anak anak papua jadi pintar pintar gerakan indonesia mengajar tak bisa di lupakan sama warga papua kami ingin bapa jadi presiden                                                                                                                                                                                                                                                             |0.0  |1.0       |\n",
      "|bawaslu dimaki jancuk sama warga gara mencopot spanduk sementara spanduk capres lain tidak dicopot bawaslu rasa tim sukses                                                                                                                                                                                                                                                                                                                            |0.0  |0.0       |\n",
      "|beberapa isu basi terkait dan fakta sebenarnya bisa dilihat di beberapa diantaranya akan mengganti pancasila dengan sistem khilafah terkait toleransi berbagai penganut agama blunder soal data rumah ibadah di jakaa mengkhianati untuk jadi capres saat kebenaran dan fakta atas suatu hal telah jelas tapi tetap disangkalentah karena niat jahat nafsu atau kepentingan pribadibenar bahwa seringkali yang buta itu bukan mata tapi hati yang buta|3.0  |3.0       |\n",
      "|menekankan pentingnya persiapan dalam kebutuhan dasar alutsista dari tiga matra yaitu darat laut dan udara mnang                                                                                                                                                                                                                                                                                                                                      |2.0  |2.0       |\n",
      "|calon presiden capres nomor urut sudah siap dengan kemampuannya menghadapi debat ketiga debat ketiga akan menyangkut tema soal peahanan keamanan hubungan internasional dan geopolitik download di app store play store                                                                                                                                                                                                                               |2.0  |2.0       |\n",
      "|capres punya rencana besar dia bakal bersinergi sama perguruan tinggi buat program yang membawa perubahan positif                                                                                                                                                                                                                                                                                                                                     |0.0  |0.0       |\n",
      "|dengan pendapatan apbd jumbo paling besar seindonesia mencapai rp                                                                                                                                                                                                                                                                                                                                                                                     |4.0  |4.0       |\n",
      "|kenyataan yg timbul menghancurkan pribadi yg isinya penuh kebencian ke ayahbowo adalahkita menimbulkan dampak emosional di pemilih dukungantulus untuk                                                                                                                                                                                                                                                                                                |0.0  |0.0       |\n",
      "|mas bawa data dan ngasih peanyaan berdasar data bisa saja dijawab oleh pak tanpa bilang data dari mas salah tapi karena pak bilang datanya salah wajar jika mas minta ditunjukkan mana data yang benar gak ada urusan sama waktu yang singkat                                                                                                                                                                                                         |0.0  |0.0       |\n",
      "|trending on twitter x bubble meroket fenomena fans kpop join isme                                                                                                                                                                                                                                                                                                                                                                                     |1.0  |1.0       |\n",
      "|wait wait pak ada bukti pak gunakan politik identitas bukankah justru ahok yang terang terangan bahkan sebelum pilkada saja sudah memantik perselisihan misal gunakan password wifi dengan kata kafir berpikir adil itu memang sulit pak                                                                                                                                                                                                              |0.0  |0.0       |\n",
      "|siti atikoh mengunjungi kantor tpd sumatera selatan atikoh mendapat kejutan dari penyandang tuna rungu simpatisan di hari tuna rungu nasional  atikoh diberikan kejutan berupa kaos warna merah beuliskan ibu negara indonesia di bagian depan tak hanya diberikan kejutan atikoh juga diajarkan bahasa isyarat                                                                                                                                       |0.0  |0.0       |\n",
      "+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"text\", \"label\", \"prediction\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 0.90323520839575\n"
     ]
    }
   ],
   "source": [
    "predictions = predictions.withColumn(\"is_correct\", F.when(F.col(\"label\") == F.col(\"prediction\"), 1).otherwise(0))\n",
    "\n",
    "class_metrics = predictions.groupBy(\"label\").agg(\n",
    "    F.sum(\"is_correct\").alias(\"TP\"),\n",
    "    F.count(\"label\").alias(\"total_samples\")\n",
    ")\n",
    "\n",
    "class_metrics = class_metrics.withColumn(\"FN\", F.col(\"total_samples\") - F.col(\"TP\"))\n",
    "\n",
    "class_metrics = class_metrics.withColumn(\"recall\", F.col(\"TP\") / (F.col(\"TP\") + F.col(\"FN\")))\n",
    "\n",
    "balanced_accuracy = class_metrics.select(F.mean(\"recall\")).collect()[0][0]\n",
    "\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.drop('conversation_id_str').drop('created_at').drop('favorite_count').drop('id_str').drop('image_url').drop('in_reply_to_screen_name').drop('lang').drop('location').drop('quote_count').drop('reply_count').drop('retweet_count').drop('tweet_url').drop('user_id_str').drop('username')\n",
    "df_test = df_test.withColumnRenamed('full_text','text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase\n",
    "df_test = df_test.withColumn(\"text\", lower(df_test[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Retweet\n",
    "df_test = df_test.withColumn(\"retweet\", when(col(\"text\").contains(\"rt\"), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(replace(text, 'rt', ''))\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Mention\n",
    "df_test = df_test.withColumn(\"mention\", when(col(\"text\").contains(\"@\"), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'@\\S+', '').alias(\"text\"))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Hastag\n",
    "df_test = df_test.withColumn(\"hashtag\", when(col(\"text\").contains(\"#\"), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'#\\S+', '').alias(\"text\"))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check URL\n",
    "df_test = df_test.withColumn(\"url\", when(col(\"text\").rlike(r'https?://\\S+'), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'https?://\\S+', '').alias(\"text\"))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Reoly\n",
    "df_test = df_test.withColumn(\"reply\", when(col(\"text\").rlike(r'\\[.*?\\]'), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\[.*?\\]', ''))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Candidate01\n",
    "df_test = df_test.withColumn(\"candidate01\", when(col(\"text\").rlike(r'\\b(anies|baswedan|muhaimin|imin|iskandar|abah|amin|01|1)\\b'), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\b(anies|baswedan|muhaimin|imin|iskandar|abah|amin|01|1)\\b', '').alias(\"text\"))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Candidate02\n",
    "df_test = df_test.withColumn(\"candidate02\", when(col(\"text\").rlike(r'\\b(prabowo|subianto|gibran|rakabuming|rakabumingraka|raka|pragib|prabowo-gibran|02|2)\\b'), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\b(prabowo|subianto|gibran|rakabuming|rakabumingraka|raka|pragib|prabowo-gibran|02|2)\\b', '').alias(\"text\"))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Candidate03\n",
    "df_test = df_test.withColumn(\"candidate03\", when(col(\"text\").rlike(r'\\b(ganjar|pranowo|mahfud|md|prof|ganjar-pranowo|03|3)\\b'), True).otherwise(False))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\b(ganjar|pranowo|mahfud|md|prof|ganjar-pranowo|03|3)\\b', '').alias(\"text\"))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text White Space\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'[^\\w\\s]', ''))\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\s+', ' '))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Number\n",
    "df_test = df_test.withColumn(\"text\", regexp_replace(col(\"text\"), r'\\d+', ''))\n",
    "df_test = df_test.withColumn(\"text\", expr(\"trim(text)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new = lr_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_new = predictions_new.drop('retweet').drop('mention').drop('hashtag').drop('url').drop('reply').drop('candidate01').drop('candidate02').drop('candidate03').drop('words_token').drop('filtered_words').drop('raw_features').drop('rawPrediction').drop('probability').drop(\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|text                                                                                                                                                                                                                                                                         |label           |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "|zaken itu apaan                                                                                                                                                                                                                                                              |politik         |\n",
      "|waalaikum salam tetap semangat karna kita akan punya presiden baru selamat menyaksikan pelantikan presiden periode versi baru kabinet stock lama alias zaken                                                                                                                 |politik         |\n",
      "|ini yg dinamakan zaken kabinet kita pikir akan ada perubahan besar yg lbh baik jk dipimpin jenderal besar ternyata aib besar yg berkepanjangan serius ga sih kelola negara                                                                                                   |politik         |\n",
      "|siapa pak yg mau mantan atau yg akan lanjutkan soalnya yg lanjutkan   juga apa kabar kabinet zaken yg tepat kabinet parpol                                                                                                                                                   |politik         |\n",
      "|zaken dalam kamus dia yaa sepei itu                                                                                                                                                                                                                                          |politik         |\n",
      "|soalnya zaken kabinet bro                                                                                                                                                                                                                                                    |politik         |\n",
      "|zaken kabinet kabinet para ahli kabinet akan mulai bekerja pada  oktober ada ahli ngibul ahli nyontek ahli adu domba ahli bikin hoax dan berbagai macam ahli lainnya                                                                                                         |politik         |\n",
      "|katanya zaken kabinet ternyata dwikora kabinet rasa  n terlalu gemoy huph                                                                                                                                                                                                    |politik         |\n",
      "|ngalamat mau ada goro goro jika kabinet zaken ternyata kabinetnya orang orang yang banyak masalah dan diragukan integritas dan kemampuan nya                                                                                                                                 |politik         |\n",
      "|semoga bapak satu pandangan soal isu palestina bahwa zionis israel penjajah ibukota iluminati harus hengkang dari palestina dan palestina harus merdeka dan jangan sampai bapak masukan manusia sepei permadi arya sang pembela zionis masuk menjadi team kabinet zaken bapak|sosial budaya   |\n",
      "|zaken atau seken                                                                                                                                                                                                                                                             |politik         |\n",
      "|bukan zaken tapi seken                                                                                                                                                                                                                                                       |politik         |\n",
      "|indonesia tidak kekurangan melahirkan orang kompeten hanya saja indonesia berlebihan melahirkan orang tidak kompeten harus dipaksa kompeten yg bukan dibidangnya sebenarnya kalau kabinet  bisa di bikin zaken sangat mungkin tapi sistem indonesia masih begini agak susah  |sumber daya alam|\n",
      "|mengusung sistem kabinet zaken yang mana akan diisi oleh para ahliprofesional dibidangnya ini salah satu langkah yang dilakukan tapi apakah strategi ini akan berbuah nantinya asumsikan sp ini bahwa untuk meraih tujuan yang menjadi persoalan adalah dengan               |politik         |\n",
      "|menyoal zaken kabinet dengan wibawa presiden demisoner                                                                                                                                                                                                                       |politik         |\n",
      "|wah parah punya gelar bodong didpt dari diplomatik tanpa ikut kuliah ditambah jd bandar judi ko bisa terpilih menjadi wamen di kabinet zaken kim plus keanehan yg luar biasa terjadi di ketatanegaraan indonesia                                                             |ideologi        |\n",
      "|katanya zaken ini berapa banyak yang emang profesional ahli di bidangnya mana yang cuma titipan paai                                                                                                                                                                         |politik         |\n",
      "|kebohongan peama rezim baru braw zaken kabinet ternyata emang agak banyak profesionalnya tapi kursi ditambah dan mayoritas masih politisi tunggu besok aja komposisi resminya                                                                                                |politik         |\n",
      "|kabinet zaken apa kabinet gemoy sih pak                                                                                                                                                                                                                                      |politik         |\n",
      "|antara kabinet seken vs kabinet gemoy vs kabinet zaken vs kabinet sterilpemangku negeri pd keblinger janji jadilah saksi di akherat nanti buat  persen                                                                                                                       |politik         |\n",
      "+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reverse Label Encoding\n",
    "predictions_new = predictions_new.withColumn(\n",
    "    \"label\", \n",
    "    when(col(\"prediction\") == 0.0, \"politik\")\n",
    "    .when(col(\"prediction\") == 1.0, \"sosial budaya\")\n",
    "    .when(col(\"prediction\") == 2.0, \"pertahanan dan keamanan\")\n",
    "    .when(col(\"prediction\") == 3.0, \"ideologi\")\n",
    "    .when(col(\"prediction\") == 4.0, \"ekonomi\")\n",
    "    .when(col(\"prediction\") == 5.0, \"sumber daya alam\")\n",
    "    .when(col(\"prediction\") == 6.0, \"demografi\")\n",
    "    .when(col(\"prediction\") == 7.0, \"geografi\")\n",
    ")\n",
    "\n",
    "predictions_new = predictions_new.drop('prediction')\n",
    "predictions_new.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+-----+\n",
      "|label                  |count|\n",
      "+-----------------------+-----+\n",
      "|sumber daya alam       |14   |\n",
      "|ideologi               |20   |\n",
      "|ekonomi                |16   |\n",
      "|sosial budaya          |13   |\n",
      "|pertahanan dan keamanan|9    |\n",
      "|politik                |357  |\n",
      "+-----------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_counts = predictions_new.groupBy(\"label\").agg(F.count(\"label\").alias(\"count\"))\n",
    "label_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_output_path = \"./output\"\n",
    "predictions_new.coalesce(1).write.option(\"header\", \"true\").csv(csv_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
